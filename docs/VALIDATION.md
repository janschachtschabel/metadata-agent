# üîç Validierung & Normalisierung im Metadata-Agent

## √úberblick

Die Validierung arbeitet **zweistufig** nach jedem Extraktionsschritt: Zun√§chst werden die von GPT-5 extrahierten Werte **normalisiert** (bereinigt), anschlie√üend gegen die **Schema-Regeln** validiert. Dieser Prozess stellt sicher, dass alle Metadaten konsistent, sauber und regelkonform gespeichert werden.

## Workflow: Schema ‚Üí Extraktion ‚Üí Validierung

### 1. Schema-Definition (core.json, event.json, etc.)

Jedes Feld im Schema enth√§lt Validierungs- und Normalisierungsregeln:

```json
{
  "id": "cclom:title",
  "prompt": {
    "label": "Titel",
    "description": "Aussagekr√§ftiger Titel der Ressource"
  },
  "system": {
    "datatype": "string",
    "required": true,
    "normalization": {
      "trim": true,              // Whitespace entfernen
      "collapseWhitespace": true // Mehrfach-Spaces reduzieren
    }
  }
}
```

Bei **Vocabularies** (kontrollierte Wertelisten):

```json
{
  "id": "cclom:educational_context",
  "vocabulary": {
    "type": "closed",           // Nur definierte Werte erlaubt
    "source": "context_vocab",
    "concepts": [
      {"id": "berufliche_bildung", "label": "Berufliche Bildung"},
      {"id": "hochschule", "label": "Hochschule"}
    ]
  }
}
```

### 2. Extraktion durch GPT-5

Der Agent sendet den User-Text an GPT-5-mini mit allen relevanten Feldern. GPT-5 extrahiert strukturierte Daten:

```python
# Beispiel: User-Input
"Ein Python-Kurs  f√ºr  Anf√§nger   an der Hochschule"

# GPT-5 extrahiert:
{
  "cclom:title": "  Python-Kurs  f√ºr  Anf√§nger  ",
  "cclom:educational_context": "Hochschule"
}
```

### 3. Normalisierung (`validator.normalize_value()`)

F√ºr **jeden** extrahierten Wert wird die Normalisierung aus dem Schema angewendet:

**Regel: `trim: true`**
```python
"  Python-Kurs  " ‚Üí "Python-Kurs"
```

**Regel: `collapseWhitespace: true`**
```python
"Kurs  f√ºr  Anf√§nger" ‚Üí "Kurs f√ºr Anf√§nger"
```

**Regel: `lowercase: true`**
```python
"PYTHON" ‚Üí "python"
```

**Regel: `deduplicate: true` (bei Arrays)**
```python
["Python", "python", "Python"] ‚Üí ["Python"]
```

### 4. Validierung (`_validate_and_normalize_fields()`)

Nach der Normalisierung werden die Werte gegen Schema-Regeln gepr√ºft:

#### a) **Vocabulary-Validierung** (closed vocabularies)

```python
# Schema definiert: ["Berufliche Bildung", "Hochschule"]
# GPT-5 extrahiert: "Universit√§t"

‚Üí Warnung: "‚ö†Ô∏è Ung√ºltiger Wert: 'Universit√§t' 
            Erlaubt: Berufliche Bildung, Hochschule"
```

#### b) **Datentyp-Validierung**

```python
# Schema: datatype="date"
# GPT-5 extrahiert: "07.10.2025"

‚Üí Warnung: "‚ö†Ô∏è Ung√ºltiges Datumsformat (erwartet: YYYY-MM-DD)"
```

#### c) **Pflichtfeld-Validierung**

```python
# Schema: required=true
# Feld leer oder fehlt

‚Üí Agent fragt nach: "‚ùå Titel: Bitte angeben"
```

### 5. Ergebnis & Fehlerbehandlung

**Bei erfolgreicher Validierung:**
- Normalisierte, validierte Werte werden im `WorkflowState` gespeichert
- User sieht saubere Daten im UI
- JSON-Export enth√§lt konsistente Metadaten

**Bei Validierungswarnungen:**
- Warnungen werden im **Terminal geloggt** (f√ºr Debugging)
- Wert wird trotzdem gespeichert (keine harte Blockierung)
- Agent kann User nach Korrektur fragen

## Integration in den Agent

Die Validierung ist **transparent** in `_extract_fields()` integriert:

```python
def _extract_fields(self, text: str, fields: List[Field], ...):
    # 1. GPT-5 extrahiert Rohwerte
    raw_extracted = gpt5_extract(text, fields)
    
    # 2. Validierung & Normalisierung
    normalized, warnings = self._validate_and_normalize_fields(
        raw_extracted, 
        fields
    )
    
    # 3. Warnungen loggen
    if warnings:
        for w in warnings:
            print(f"üîç {w}")
    
    # 4. Normalisierte Werte zur√ºckgeben
    return normalized
```

**Wird automatisch aufgerufen bei:**
- Core-Pflichtfelder (Phase 2)
- Core-Optionale Felder (Phase 3)
- Spezial-Schema Pflichtfelder (Phase 5a)
- Spezial-Schema Optionale Felder (Phase 5b)

## Vorteile

‚úÖ **Datenqualit√§t**: Keine Duplikate, konsistentes Whitespace, g√ºltige Formate  
‚úÖ **Schema-Konformit√§t**: Werte entsprechen definierten Vocabularies  
‚úÖ **Automatisch**: Keine manuelle Nachbearbeitung n√∂tig  
‚úÖ **Transparent**: Warnungen im Log f√ºr Debugging  
‚úÖ **Flexibel**: Pro Feld konfigurierbar via Schema

## Beispiel: End-to-End

**Input:**
```
"Ein  PYTHON-Kurs   f√ºr Anf√§nger an der Universit√§t"
```

**Extraktion (GPT-5):**
```json
{
  "cclom:title": "  PYTHON-Kurs   f√ºr Anf√§nger  ",
  "cclom:general_keyword": ["Python", "python", "Anf√§nger"],
  "cclom:educational_context": "Universit√§t"
}
```

**Nach Validierung:**
```json
{
  "cclom:title": "PYTHON-Kurs f√ºr Anf√§nger",
  "cclom:general_keyword": ["Python", "Anf√§nger"],
  "cclom:educational_context": "Hochschule"
}
```

**Warnungen:**
```
‚ö†Ô∏è educational_context: 'Universit√§t' nicht erlaubt ‚Üí Korrektur zu 'Hochschule'
```

---

**Fazit:** Die Validierung stellt sicher, dass extrahierte Metadaten **automatisch bereinigt und gegen Schema-Regeln gepr√ºft** werden, bevor sie im Workflow gespeichert werden. Dies garantiert konsistente, hochwertige Metadaten ohne manuelle Nacharbeit.
