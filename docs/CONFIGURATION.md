# âš™ï¸ Konfiguration via .env

Alle wichtigen Einstellungen kÃ¶nnen Ã¼ber die `.env`-Datei gesteuert werden.

## ğŸš€ Quick Start

### 1. .env-Datei erstellen

```bash
# Kopiere die Vorlage
cp .env.example .env

# Oder erstelle manuell:
# Windows PowerShell:
Copy-Item .env.example .env

# Linux/Mac:
cp .env.example .env
```

### 2. API Key eintragen

Ã–ffne `.env` und trage deinen OpenAI API Key ein:

```env
OPENAI_API_KEY=sk-proj-...
```

### 3. Fertig!

Der Agent lÃ¤dt automatisch alle Einstellungen aus der `.env`:

```python
from agent import MetadataAgent

# LÃ¤dt automatisch: API Key, Model, Base URL, Reasoning, Verbosity
agent = MetadataAgent()
```

---

## ğŸ“‹ VerfÃ¼gbare Einstellungen

### **OPENAI_API_KEY** (Pflicht)

```env
OPENAI_API_KEY=sk-proj-xxxxx
```

**Beschreibung:** Dein OpenAI API Key  
**Bezugsquelle:** https://platform.openai.com/api-keys  
**Erforderlich:** âœ… Ja

---

### **OPENAI_MODEL** (Optional)

```env
OPENAI_MODEL=gpt-5-mini
```

**Beschreibung:** Welches GPT-5 Modell verwendet werden soll  
**Standard:** `gpt-5-mini`  
**Optionen:**
- `gpt-5-mini` - Empfohlen (beste Balance)
- `gpt-5-nano` - Schneller, weniger leistungsfÃ¤hig

---

### **OPENAI_BASE_URL** (Optional)

```env
# OPENAI_BASE_URL=https://api.openai.com/v1
```

**Beschreibung:** OpenAI API Basis-URL  
**Standard:** `https://api.openai.com/v1` (wenn nicht gesetzt)  
**AnwendungsfÃ¤lle:**
- Proxy-Server verwenden
- Custom OpenAI Endpoints
- Azure OpenAI Service
- LiteLLM Gateway

**Beispiele:**

```env
# Azure OpenAI
OPENAI_BASE_URL=https://your-resource.openai.azure.com

# LiteLLM Proxy
OPENAI_BASE_URL=http://localhost:4000

# Custom Proxy
OPENAI_BASE_URL=https://proxy.company.com/openai
```

---

## ğŸ”€ Andere Modelle (GPT-4, GPT-3.5, etc.)

Wenn du ein **anderes Modell** als GPT-5 verwendest:

```env
# Beispiel: GPT-4o
OPENAI_API_KEY=sk-proj-xxxxx
OPENAI_MODEL=gpt-4o

# Diese Parameter werden IGNORIERT (nur fÃ¼r GPT-5):
# GPT5_REASONING_EFFORT=minimal
# GPT5_VERBOSITY=low
```

**Automatische API-Auswahl:**
- GPT-5 Modelle (`gpt-5*`): Nutzt Responses API mit reasoning/verbosity
- Andere Modelle: Nutzt Chat Completions API (Standard)

**UnterstÃ¼tzte Modelle:**
- âœ… `gpt-5-mini`, `gpt-5-nano`, `gpt-5`
- âœ… `gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`
- âœ… `gpt-3.5-turbo`
- âœ… Kompatible Models via Custom Base URL

---

## ğŸ¯ Empfohlene Konfigurationen

### **Standard (Optimal fÃ¼r Produktion mit GPT-5):**

```env
OPENAI_API_KEY=sk-proj-xxxxx
OPENAI_MODEL=gpt-5-mini
GPT5_REASONING_EFFORT=minimal
GPT5_VERBOSITY=low
```

**Performance:** âš¡ Schnell (~15-20s)  
**QualitÃ¤t:** âœ… Gut fÃ¼r strukturierte Extraktion  
**Kosten:** ğŸ’° Niedrig

---

### **Hohe QualitÃ¤t (fÃ¼r schwierige Texte):**

```env
OPENAI_API_KEY=sk-proj-xxxxx
OPENAI_MODEL=gpt-5-mini
GPT5_REASONING_EFFORT=low
GPT5_VERBOSITY=medium
```

**Performance:** ğŸŒ Langsamer (~30-40s)  
**QualitÃ¤t:** âœ…âœ… Besser bei komplexen Texten  
**Kosten:** ğŸ’°ğŸ’° Mittel

---

### **Development/Debugging (mit GPT-5):**

```env
OPENAI_API_KEY=sk-proj-xxxxx
OPENAI_MODEL=gpt-5-mini
GPT5_REASONING_EFFORT=medium
GPT5_VERBOSITY=high
```

**Performance:** ğŸŒğŸŒ Langsam (~50-80s)  
**QualitÃ¤t:** âœ…âœ…âœ… Maximum + Detaillierte Antworten  
**Kosten:** ğŸ’°ğŸ’°ğŸ’° Hoch

---

### **Alternative: GPT-4o (Wenn GPT-5 nicht verfÃ¼gbar):**

```env
OPENAI_API_KEY=sk-proj-xxxxx
OPENAI_MODEL=gpt-4o
# GPT5_REASONING_EFFORT und GPT5_VERBOSITY werden ignoriert
```

**Performance:** âš¡ Schnell (~10-15s)  
**QualitÃ¤t:** âœ…âœ… Sehr gut fÃ¼r strukturierte Extraktion  
**Kosten:** ğŸ’°ğŸ’° Mittel  
**Note:** Nutzt automatisch Chat Completions API mit temperature=0.1

---

## ğŸ”§ Erweiterte Nutzung

### **Parameter in Code Ã¼berschreiben:**

Du kannst die .env-Werte auch im Code Ã¼berschreiben:

```python
from agent import MetadataAgent

# Nutzt .env fÃ¼r alles auÃŸer reasoning_effort
agent = MetadataAgent(reasoning_effort="high")

# Ãœberschreibt mehrere Werte
agent = MetadataAgent(
    model="gpt-5-nano",
    reasoning_effort="low",
    verbosity="medium"
)

# Komplett manuell (ignoriert .env)
agent = MetadataAgent(
    api_key="sk-proj-xxxxx",
    model="gpt-5-mini",
    base_url="https://custom.api.com",
    reasoning_effort="minimal",
    verbosity="low"
)
```

---

### **Verschiedene Umgebungen:**

```bash
# Development
.env.development

# Production
.env.production

# Testing
.env.test
```

**Laden:**

```python
from dotenv import load_dotenv

# Lade spezifische .env
load_dotenv('.env.production')

agent = MetadataAgent()
```

---

## ğŸ” Troubleshooting

### **Fehler: "OPENAI_API_KEY not provided"**

**Ursache:** `.env` fehlt oder API Key nicht gesetzt

**LÃ¶sung:**

```bash
# 1. PrÃ¼fe ob .env existiert
ls -la .env

# 2. Erstelle .env aus Vorlage
cp .env.example .env

# 3. Trage API Key ein
# Ã–ffne .env und setze: OPENAI_API_KEY=sk-proj-xxxxx
```

---

### **Fehler: "Invalid GPT-5 model"**

**Ursache:** UngÃ¼ltiges Model in `.env`

**LÃ¶sung:**

```env
# Nur diese Werte erlaubt:
OPENAI_MODEL=gpt-5-mini  # âœ…
OPENAI_MODEL=gpt-5-nano  # âœ…
OPENAI_MODEL=gpt-4       # âŒ Nicht unterstÃ¼tzt
```

---

### **Langsame Performance (>30s)**

**Ursachen:**
1. `GPT5_REASONING_EFFORT` zu hoch gesetzt
2. `GPT5_VERBOSITY` zu hoch gesetzt
3. OpenAI Rate Limits

**LÃ¶sung:**

```env
# Setze auf optimale Werte:
GPT5_REASONING_EFFORT=minimal
GPT5_VERBOSITY=low
```

**Test:**

```bash
# Messe aktuelle Performance:
python test_api_latency.py

# Erwartete Zeit pro Call:
# âœ… <1.5s: Optimal
# âš ï¸ 1.5-3s: Akzeptabel
# âŒ >3s: Rate Limits oder zu hohe Einstellungen
```

---

### **Base URL funktioniert nicht**

**Beispiel:** Azure OpenAI

```env
# âŒ Falsch (v1 fehlt):
OPENAI_BASE_URL=https://your-resource.openai.azure.com

# âœ… Richtig:
OPENAI_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/YOUR-DEPLOYMENT-NAME
```

---

## ğŸ“Š Performance-Matrix

| reasoning_effort | verbosity | Zeit/Workflow | QualitÃ¤t | Kosten |
|------------------|-----------|---------------|----------|--------|
| minimal | low | ~15-20s | â­â­â­ | ğŸ’° |
| minimal | medium | ~20-25s | â­â­â­ | ğŸ’°ğŸ’° |
| low | low | ~25-30s | â­â­â­â­ | ğŸ’°ğŸ’° |
| low | medium | ~30-40s | â­â­â­â­ | ğŸ’°ğŸ’°ğŸ’° |
| medium | low | ~40-50s | â­â­â­â­â­ | ğŸ’°ğŸ’°ğŸ’° |
| medium | medium | ~50-60s | â­â­â­â­â­ | ğŸ’°ğŸ’°ğŸ’°ğŸ’° |
| high | high | ~80-120s | â­â­â­â­â­ | ğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’° |

**Empfehlung:** `minimal` + `low` = Beste Balance! âš¡

---

## âœ… Zusammenfassung

### **Minimale Konfiguration (Nur API Key):**

```env
OPENAI_API_KEY=sk-proj-xxxxx
```

Alle anderen Werte werden automatisch auf optimale Defaults gesetzt!

### **Code bleibt einfach:**

```python
# Alles aus .env
agent = MetadataAgent()
```

### **Flexibel bei Bedarf:**

```python
# Ãœberschreibe einzelne Werte
agent = MetadataAgent(reasoning_effort="high")
```

**Fertig! ğŸ‰**
